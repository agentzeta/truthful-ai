# truthful-ai
Community built knowledge repository of consensus-verified AI answers to user generated questions across a vast array of domains
# What is truthful-ai?
Truthful-ai is a platform for a community-built knowledge-hub like quora/wikipedia based on consensus learning, but with responses generated by multiple LLMs and consensus verified using statistical techniques. The Consensus responses to questions are verified and date and time stamped and stored permanentsly on a decentralised blockchain storage system (Flare) , along with a transaction hash. The app also gives a leader board for scoring models on consensus, anti-hallucination, consistency etc which creates useful dynamically evolving signals for public consumption of model generated outputs, and also a necessary step towards an industry benchmark for evaluating models - which is a hard problem to solve. The cumulative knowledge becomes an  invaluable repository of intellectual capital or a public good over time. The potential applications are numerous, both for commercial use and for highly confidential repositories for private use and reference such as in medical field. For example, overtime, this platform can potentially evolve to be a highly relaiable medical repository where doctors and healthcare providers can look up medical issue related queries for diagnosis and treatment, and can rely with a high confidence interval on the consensus responses. This innovation makes this verifiable AI tool useful for even medical novices as it eliminates the serious issue of unreliability and hallucinations and wild extrapolations that the LLMs can be prone to oftentimes. Naturally, this verifiable AI tool can be used across a myriad domains in technology, science, scientific discovery, manufacturing, STEM fields, education, health, space, and even mundane things like consumer goods, travel, and personal finance.

# What techniques are used for arriving at Verifiable Consensus?
The consensus derivation logic has been built from the ground up, without relying on external applications such as openrouter's consensus which relies on aggregating/synthesising LLM responses. Below are some key parameters assessed to arrive at a consensus logic. 
Consensus-Based Verification: A response is "verified" if it's highly similar to the consensus response
Jaccard Similarity Threshold: Using our existing Jaccard similarity calculation to determine if a response is close to the consensus
Confidence Score: Responses with higher confidence scores are more likely to be verified  
Similarity Calculation: A function to calculate Jaccard similarity between responses based on shared words, which helps identify when models are saying similar things in different ways.
Outlier Detection: A method to identify and remove outlier responses that have low average similarity with other responses.
Clustering Algorithm: A clustering approach that groups responses based on their similarity, allowing us to identify the "majority opinion" among the models.
Consensus Extraction: Logic to extract the common information from the largest cluster of similar responses, with priority given to higher confidence responses within that cluster.
Confidence Calculation: A system to calculate the overall confidence in the consensus based on:
The proportion of models that agree (cluster size relative to total responses)
The average confidence scores of models in the majority cluster

# Why is this tool important?
In a world of abundant generative AI, we need tools to parse truth from fiction, and be able to consider information with some confidence, so this tool tries to compare multiple (LLM) model outputs to arrive at a single consensus response (with text that is extracted from multiple models with statistical rigor ), which can be stored in decentralised public annals, with timestamps for relevance. 
Informative Output: The app generates a consensus response from multiple LLM outputs, after eliminating wild hallucinations and outlier responses, and the output includes confidence levels and a disclaimer about the nature of AI-generated advice, which is especially important for medical contexts.
Analysis Function: A function that provides detailed analysis of the consensus visually and textually.
This implementation eliminates outlier responses through similarity analysis
Includes only high-consensus information by clustering similar responses
Provides confidence intervals through the consensus confidence calculation
Suitable for high fidelity scenarios such as medical diagnosis by emphasizing agreement among models and including appropriate disclaimers
The system now provides not just a single response (consensus response along with a verified model output), but information about how confident we can be in that consensus, which is crucial for critical applications requiring precision and accuracy like medical diagnosis, space, scientific missions etc.
While this is not meant to be a substitute for human precision and judgement, tools such as this are a step towards Artificial General Intelligence.

# Technical Implementation 
A Community-built, Verifiable Knowledge Base
truthful.ai is a platform driven by AI for consensus learning that generates and validates knowledge through multi-model verification, statistical analysis, and blockchain-based immutability.

# Overview
truthful.ai addresses a critical challenge in the AI era: determining the reliability of information. By leveraging multiple LLM responses to the same query, analyzing their consensus patterns, and permanently recording verified answers, we create a trustworthy knowledge repository that grows more valuable over time.

# What technologies are used for this project?
This project is built with:

Vite
TypeScript
React
shadcn-ui
Tailwind CSS
Multiple LLMs and AI apps

# Key Features
Multi-model Consensus: Queries multiple AI models for verification
Statistical Validation: Analyzes response similarity and confidence metrics
Blockchain Permanence: Stores verified answers on Flare blockchain TEE
Temporal Context: Timestamps all knowledge entries for relevance tracking
Community Governance: Enables community participation in knowledge validation

# How It Works
User submits a query to the truthful.ai platform
System distributes the query to multiple LLM endpoints
AI models generate independent responses
Consensus engine analyzes responses for similarity and confidence
System generates a consolidated answer with statistical metrics
Verified knowledge is stored on the blockchain with timestamp
Knowledge base grows as a valuable intellectual asset and public good
Getting Started
Prerequisites
Node.js v16+
Python 3.9+
API keys for supported LLMs
Flare network access credentials
Installation
bash

Copy
git clone https://github.com/agentzeta/trusted-knowledge-hub.git
cd trusted-knowledge-hub
npm install
Configuration
Create a .env file in the root directory with the following variables:


Copy
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
FLARE_NODE_URL=your_flare_node_url
FLARE_PRIVATE_KEY=your_flare_private_key
Running the Application
bash

Copy
npm start
The application will be available at http://localhost:3000.

# Project Structure

Copy
trusted-knowledge-hub/
├── client/                # Frontend React application
├── server/                # Backend Node.js server
│   ├── controllers/       # Request handlers
│   ├── models/            # Data models
│   ├── services/          # Business logic
│   │   ├── ai-services/   # LLM integration
│   │   └── blockchain/    # Flare blockchain integration
│   └── utils/             # Helper functions
├── consensus-engine/      # Python-based consensus analysis
└── docs/                  # Documentation
Contribution
truthful.ai is designed as a community project. Contributions are welcome in the following areas:

# Adding support for additional LLM providers
Improving consensus algorithms
Enhancing the user interface
Building tools to explore the knowledge base
Developing governance mechanisms
Please see CONTRIBUTING.md for details.

# Roadmap
Phase 1: Initial platform with basic consensus engine and blockchain storage
Phase 2: Enhanced statistical analysis and confidence metrics
Phase 3: Community governance mechanisms
Phase 4: API access to the verified knowledge base
Phase 5: Integration with other knowledge tools and platforms
License
This project is licensed under the MIT License - see the LICENSE file for details.
This project was created at UC Berkely campus 2025 for a coding challenge.

# Contact
GitHub: https://github.com/agentzeta/trusted-knowledge-hub
Email: himalayalabs@gmail.com

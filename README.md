# truthful-ai
Community built knowledge repository of consensus-verified AI answers to user generated questions across a vast array of domains
# What is truthful-ai?
Truthful-ai is a platform for a community-built knowledge-hub like quora/wikipedia based on consensus learning, but with responses generated by multiple LLMs and consensus verified using statistical techniques. The Consensus responses to questions are verified and date and time stamped and stored permanentsly on a decentralised blockchain storage system (Flare) , along with a transaction hash. The app also gives a leader board for scoring models on consensus, anti-hallucination, consistency etc which creates useful dynamically evolving signals for public consumption of model generated outputs, and also a necessary step towards an industry benchmark for evaluating models - which is a hard problem to solve. The cumulative knowledge becomes an  invaluable repository of intellectual capital or a public good over time. The potential applications are numerous, both for commercial use and for highly confidential repositories for private use and reference such as in medical field. For example, overtime, this platform can potentially evolve to be a highly relaiable medical repository where doctors and healthcare providers can look up medical issue related queries for diagnosis and treatment, and can rely with a high confidence interval on the consensus responses. This innovation makes this verifiable AI tool useful for even medical novices as it eliminates the serious issue of unreliability and hallucinations and wild extrapolations that the LLMs can be prone to oftentimes. Naturally, this verifiable AI tool can be used across a myriad domains in technology, science, scientific discovery, manufacturing, STEM fields, education, health, space, and even mundane things like consumer goods, travel, and personal finance.

# What technologies are used for this project?
This project is built with:

Vite
TypeScript
React
shadcn-ui
Tailwind CSS
Multiple LLMs and AI apps

# What techniques are used for arriving at Verifiable Consensus?
The consensus derivation logic has been built from the ground up, without relying on external applications such as openrouter's consensus which relies on aggregating/synthesising LLM responses. Below are some key parameters assessed to arrive at a consensus logic. 
Consensus-Based Verification: A response is "verified" if it's highly similar to the consensus response
Jaccard Similarity Threshold: Using our existing Jaccard similarity calculation to determine if a response is close to the consensus
Confidence Score: Responses with higher confidence scores are more likely to be verified  
Similarity Calculation: A function to calculate Jaccard similarity between responses based on shared words, which helps identify when models are saying similar things in different ways.
Outlier Detection: A method to identify and remove outlier responses that have low average similarity with other responses.
Clustering Algorithm: A clustering approach that groups responses based on their similarity, allowing us to identify the "majority opinion" among the models.
Consensus Extraction: Logic to extract the common information from the largest cluster of similar responses, with priority given to higher confidence responses within that cluster.
Confidence Calculation: A system to calculate the overall confidence in the consensus based on:
The proportion of models that agree (cluster size relative to total responses)
The average confidence scores of models in the majority cluster

# Why is this tool important?
In a world of abundant generative AI, we need tools to parse truth from fiction, and be able to consider information with some confidence, so this tool tries to compare multiple (LLM) model outputs to arrive at a single consensus response (with text that is extracted from multiple models with statistical rigor ), which can be stored in decentralised public annals, with timestamps for relevance. 
Informative Output: The app generates a consensus response from multiple LLM outputs, after eliminating wild hallucinations and outlier responses, and the output includes confidence levels and a disclaimer about the nature of AI-generated advice, which is especially important for medical contexts.
Analysis Function: A function that provides detailed analysis of the consensus visually and textually.
This implementation eliminates outlier responses through similarity analysis
Includes only high-consensus information by clustering similar responses
Provides confidence intervals through the consensus confidence calculation
Suitable for high fidelity scenarios such as medical diagnosis by emphasizing agreement among models and including appropriate disclaimers
The system now provides not just a single response (consensus response along with a verified model output), but information about how confident we can be in that consensus, which is crucial for critical applications requiring precision and accuracy like medical diagnosis, space, scientific missions etc.
While this is not meant to be a substitute for human precision and judgement, tools such as this are a step towards Artificial General Intelligence.
